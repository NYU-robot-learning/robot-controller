{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = \"/home/xiaohan/accel-cortex/\"\n",
    "\n",
    "import pickle\n",
    "from home_robot.core.interfaces import Observations\n",
    "import numpy as np\n",
    "\n",
    "# with open(root_path + \"debug_svm.pkl\", \"rb\") as f:\n",
    "#     svm = pickle.load(f)\n",
    "\n",
    "\n",
    "# observations = svm.observations\n",
    "# with open(root_path + \"annotation.pkl\", \"rb\") as f:\n",
    "#     annotation = pickle.load(f)\n",
    "with open(\"/home/xiaohan/Downloads/robot.pkl\", \"rb\") as f:\n",
    "    obs_history = pickle.load(f)\n",
    "\n",
    "# print(annotation[\"task\"])\n",
    "# key_frames = []\n",
    "# key_obs = []\n",
    "# for idx, obs in enumerate(observations):\n",
    "#     perceived_ids = np.unique(obs.obs.task_observations[\"gt_instance_ids\"])\n",
    "#     for target_id in annotation[\"object_ids\"]:\n",
    "#         if (target_id + 1) in perceived_ids:\n",
    "#             print(\"target observation found\")\n",
    "#             key_frames.append(obs)\n",
    "#             key_obs.append(obs_history[idx])\n",
    "# obs = key_frames[-1]\n",
    "key_obs = []\n",
    "num_obs = len(obs_history[\"rgb\"])\n",
    "\n",
    "for obs_id in range(num_obs):\n",
    "    key_obs.append(\n",
    "        Observations(\n",
    "            rgb=obs_history[\"rgb\"][obs_id].numpy(),\n",
    "            gps=obs_history[\"base_poses\"][obs_id][:2].numpy(),\n",
    "            compass=[obs_history[\"base_poses\"][obs_id][2].numpy()],\n",
    "            xyz=obs_history[\"xyz\"][obs_id].numpy(),\n",
    "            depth=obs_history[\"depth\"][obs_id].numpy(),\n",
    "            camera_pose=obs_history[\"camera_poses\"][obs_id].numpy(),\n",
    "            camera_K=obs_history[\"camera_K\"][obs_id].numpy(),\n",
    "        )\n",
    "    )\n",
    "if \"obs\" in obs_history:\n",
    "    key_obs = obs_history[\"obs\"]\n",
    "\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "import imageio\n",
    "import yaml\n",
    "from PIL import Image\n",
    "\n",
    "from home_robot.agent.multitask import get_parameters\n",
    "from home_robot.mapping.voxel import (\n",
    "    SparseVoxelMap,\n",
    "    SparseVoxelMapNavigationSpace,\n",
    "    plan_to_frontier,\n",
    ")\n",
    "from home_robot.perception import create_semantic_sensor\n",
    "from home_robot.perception.encoders import get_encoder\n",
    "\n",
    "# image_array = np.array(obs.obs.rgb, dtype=np.uint8)\n",
    "# print(image_array.shape)\n",
    "# # image_array = image_array[..., ::-1]\n",
    "# image = Image.fromarray(image_array)\n",
    "\n",
    "\n",
    "parameters = yaml.safe_load(\n",
    "    Path(\"/home/xiaohan/home-robot/src/home_robot_sim/configs/gpt4v.yaml\").read_text()\n",
    ")\n",
    "config, semantic_sensor = create_semantic_sensor()\n",
    "semantic_sensor\n",
    "\n",
    "# parameters = get_parameters(cfg.agent_parameters)\n",
    "encoder = get_encoder(parameters[\"encoder\"], parameters[\"encoder_args\"])\n",
    "\n",
    "voxel_map = SparseVoxelMap(\n",
    "    resolution=parameters[\"voxel_size\"],\n",
    "    local_radius=parameters[\"local_radius\"],\n",
    "    obs_min_height=parameters[\"obs_min_height\"],\n",
    "    obs_max_height=parameters[\"obs_max_height\"],\n",
    "    min_depth=parameters[\"min_depth\"],\n",
    "    max_depth=parameters[\"max_depth\"],\n",
    "    pad_obstacles=parameters[\"pad_obstacles\"],\n",
    "    add_local_radius_points=parameters.get(\"add_local_radius_points\", True),\n",
    "    remove_visited_from_obstacles=parameters.get(\n",
    "        \"remove_visited_from_obstacles\", False\n",
    "    ),\n",
    "    obs_min_density=parameters[\"obs_min_density\"],\n",
    "    encoder=encoder,\n",
    "    smooth_kernel_size=parameters.get(\"filters/smooth_kernel_size\", -1),\n",
    "    use_median_filter=parameters.get(\"filters/use_median_filter\", False),\n",
    "    median_filter_size=parameters.get(\"filters/median_filter_size\", 5),\n",
    "    median_filter_max_error=parameters.get(\"filters/median_filter_max_error\", 0.01),\n",
    "    use_derivative_filter=parameters.get(\"filters/use_derivative_filter\", False),\n",
    "    derivative_filter_threshold=parameters.get(\n",
    "        \"filters/derivative_filter_threshold\", 0.5\n",
    "    ),\n",
    "    instance_memory_kwargs={\n",
    "        \"min_pixels_for_instance_view\": parameters.get(\n",
    "            \"min_pixels_for_instance_view\", 100\n",
    "        ),\n",
    "        \"min_instance_thickness\": parameters.get(\"min_instance_thickness\", 0.01),\n",
    "        \"min_instance_vol\": parameters.get(\"min_instance_vol\", 1e-6),\n",
    "        \"max_instance_vol\": parameters.get(\"max_instance_vol\", 10.0),\n",
    "        \"min_instance_height\": parameters.get(\"min_instance_height\", 0.1),\n",
    "        \"max_instance_height\": parameters.get(\"max_instance_height\", 1.8),\n",
    "        \"open_vocab_cat_map_file\": parameters.get(\"open_vocab_cat_map_file\", None),\n",
    "    },\n",
    ")\n",
    "\n",
    "voxel_map.reset()\n",
    "# key_obs = key_obs[::4]\n",
    "key_obs = [key_obs[43]]\n",
    "# key_obs = key_obs[35:45]\n",
    "for idx, obs in enumerate(key_obs):\n",
    "\n",
    "    image_array = np.array(obs.rgb, dtype=np.uint8)\n",
    "    image = Image.fromarray(image_array)\n",
    "    image.show()\n",
    "\n",
    "    obs = semantic_sensor.predict(obs)\n",
    "    voxel_map.add_obs(obs)\n",
    "\n",
    "voxel_map.show(\n",
    "    instances=True,\n",
    "    height=1000,\n",
    "    boxes_plot_together=False,\n",
    "    backend=\"pytorch3d\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import imageio\n",
    "import io\n",
    "from IPython.display import HTML\n",
    "from base64 import b64encode\n",
    "\n",
    "buffer = io.BytesIO()\n",
    "\n",
    "# Create an in-memory video writer\n",
    "with imageio.get_writer(buffer, format=\"mp4\", fps=2) as video:\n",
    "    for frame in key_obs:\n",
    "        video.append_data(frame.rgb.astype(np.uint8))\n",
    "\n",
    "# Get the video content from the buffer\n",
    "video_content = buffer.getvalue()\n",
    "buffer.close()\n",
    "\n",
    "# Encode the video for HTML display\n",
    "video_encoded = b64encode(video_content).decode(\"ascii\")\n",
    "html = f'<video width=\"640\" height=\"480\" controls><source src=\"data:video/mp4;base64,{video_encoded}\" type=\"video/mp4\"></video>'\n",
    "\n",
    "# Display the video\n",
    "HTML(html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "home-robot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
